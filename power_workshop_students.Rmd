---
title: "power_workshop"
author: "Chris Jungerius"
date: "11/22/2022"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(afex)
library(lmerTest)
library(faux)
library(broom.mixed)

afex::set_sum_contrasts() # avoids annoying afex message
## setting contr.sum globally: options(contrasts=c('contr.sum', 'contr.poly'))
afex_options(include_aov = FALSE) # runs faster
afex_options(es_aov = "pes") # changes effect size measure to partial eta squared
```

Before we begin, we can set a seed so the outcome of our random number generators are identical.

```{r}
set.seed(90059)
x <- rnorm(1)

```


Let's start with the basics:
rnorm generates a sample from a population with a given mean and standard deviation. For example, to draw 100 samples from a population with mean 6 and sd 2:

```{r}
n <- #number of samples?
mu <- #population mean?
sigma <- #population sd?
  
sample = rnorm(n, mu, sigma)
mean(sample)
sd(sample)
```

We can also run statistics on these samples - for example, a one-sided t.test to test whether our sample is likely to come from a population with mu = 0

```{r}
#We use tidy here and elsewhere to clean up test summaries and coerce them to dataframes. Try leaving out the %>% tidy part and see what the data looks like then.
t.test(sample) %>% tidy
```
Or a two-sided t.test to test whether two samples are likely to come from the same population

```{r}

sample2 = rnorm(
  #?
  )
t.test(sample,sample2) %>% tidy
```

We can combine our sampling from a given population and testing (one-sided for now) into a function for convenience:

```{r}
draw_and_test <- function(
  n=10,
  mu=0,
  sigma=1
){
  
  sample <- #how do we generate a sample?
  
  
  result <- #how do we perform a t.test?
  
  
  #once we have a result, we use a 'pipeline' of verbs to modify it for our purposes:
  result <- result %>%  #input
    tidy %>%            #coerce it to a dataframe
    select(estimate,    #keep only the columns we care about
           p.value) %>% 
    mutate(             #add new columns to the dataframe to save the parameters we used
      n=n,
      mu=mu,
      sigma=sigma
    )
  
  return(result)
}

#let's try our function! Feel free to change these values and see the different results
draw_and_test(100,1,.5)

```


Cool. but what if I want to run, like, 1000 t.tests on samples drawn from a population? And stick the results in a dataframe while I'm at it?

```{r}
nreps = 1000

#crossing creates a dataframe with all combinations of parameters provided. In the case below, that means it simply repeats all parameters nrep times
params <- crossing(
  rep = seq(nreps),
  n = 10,
  mu = .5,
  sigma = 1
) %>% 
  select(-rep) #we only needed rep to create our big dataframe, but we don't need it as function input. Therefore here drop it from the params dataframe.

sims <- pmap_df(params,draw_and_test) #pmap_df maps a function (draw_and_test in our case) to all rows of a dataframe (params) and outputs the result as another dataframe. Neat!
tidy(sims)
```

Let's inspect our simulations visually:

```{r}
#We feed our dataframe into a ggplot object, to which we then add the geometries we want to use to represent our data.
sims %>% 
  #the basic object
  ggplot(
    aes(
      #the aesthetics, i.e. the columns we care about
      x = estimate
      )
  ) +
  #and now we add geometries! In this case, only a density plot of the means we found:
  geom_density() 
  #you can try changing it to another method to represent this, such as geom_histogram or geom_boxplot!
```
Or we can plot the p-values
```{r}

sims %>% 
  ggplot(
    aes(
      x = #? which column of the dataframe should we put here?
      )
  ) +
  #first a density plot of the p values:
  geom_density() +
  #and a vertical line to represent the alpha=0.05 significance cutoff
  geom_vline(
    xintercept = .05,
    linetype = "dashed"
  )
```

We can also quantify our power numerically by seeing which percentage of our tests reached significance:
```{r}
sims %>% 
  summarise(
    power = mean(p.value < .05)
  )
```
And see if the effect estimate of the tests that reached significance is inflated (if your power is low, this will definitely be the case)
```{r}
sims %>% 
  filter(p.value < .05) %>% 
  summarise(d = mean(#?of which column of the dataframe?))
```
So this already demonstrates the basics:

- generate a sample from a virtual population
- perform your statistical test of choice
- repeat many times and record the result
- detect whether you recover the effect of interest consistently (e.g. >80% of the time), for any given case, and how inflated your significant effects will be.


Of course, there's no reason to only test a single parameter value at a time. The same technique holds for a range of parameter values:

```{r}
nreps = 1000

#crossing creates a dataframe with all combinations of parameters provided. In the case below, that means it simply repeats all parameters nrep times
params <- crossing(
  rep = seq(nreps),
  n = 10,
  mu = .5,
  sigma = 1
) %>% 
  select(-rep) #we only needed rep to create our big dataframe, but we don't need it as function input. Therefore here drop it from the params dataframe.

sims <- pmap_df(params,draw_and_test) #pmap_df maps a function (draw_and_test in our case) to all rows of a dataframe (params) and outputs the result as another dataframe. Neat!
tidy(sims)
```


We can do much of this simulation work using faux's `sim_design` function. For example, a between subjects t.test would be built as follows:

```{r}

smarterpets <- sim_design(
  n=100,
  between = list(pet = c("cat", "dog")),
  mu = c(105,100),
  sd = c(10,10),
  dv = "iq"
)

head(smarterpets)
```


```{r}
t.test(iq~pet,data=smarterpets)
aov_4(iq~pet+(1|id), data=smarterpets)
```

While a within-subjects design would look like this:

```{r}

growth <- sim_design(
  n=100,
  within = list(time = c("pre", "post")),
  mu = c(90,100),
  sd = c(20,20),
  dv = "cm",
  long=TRUE
)

#paired t.test or within-subjects anova recovers the same p.value:

t.test(cm ~ time, data=growth, paired = TRUE)
aov_4(cm ~ (time | id), data=growth)
```

Factorial designs

Moving up a level, let's take a look at simulating our power to detect an interaction effect in a 2*2 factorial design using an ANOVA

```{r}
pethappy <- sim_design(
  within = list(time = c("pre", "post")),
  between = list(pet = c("cat", "dog")),
  n = #?,
  mu = data.frame(
    pre = #?,
    post = #?,
    row.names = c("cat", "dog")
  ),
  sd = 1,
  id = "pet_id",
  dv = "happiness",
  r = 0.5,
  long = TRUE
)


```

...And we can use faux's "rep" argument to repeat this dataframe many times and perform analysis on each generated dataframe

```{r}
pethappy100 <- sim_design(
  within = list(time = c("pre", "post")),
  between = list(pet = c("cat", "dog")),
  n = #?,
  mu = data.frame(
    pre = #?,
    post = #?,
    row.names = c("cat", "dog")
  ),
  sd = 1,
  id = "pet_id",
  dv = "score",
  r = 0.5,
  long = TRUE,
  rep = 100
)

analyse <- function(data){
  
  a <- aov_4(happiness ~ pet * (time | pet_id),data=data)
  
    # return anova_table for GG-corrected DF
    as_tibble(a$anova_table, rownames = "term") %>% 
    mutate(term = factor(term, levels = term))  %>%  # keeps terms in order
    rename(p.value = `Pr(>F)`) # fixes annoying p.value name
}

pethappy_sim <- map_df(pethappy100$data,analyse)

pethappy_sim  %>% 
  group_by(term)  %>% 
  summarise(power = mean(p.value < 0.05),
            mean_pes = mean(pes),
            .groups = "drop")
```

And expand THAT to generate dataframes with different properties simultaneously

```{r}

sample_sizes = seq(#?)

create_dfs <- function(n){
  
  pethappy100 <- sim_design(
  within = list(time = c("pre", "post")),
  between = list(pet = c("cat", "dog")),
  n = c(n,n),
  mu = data.frame(
    pre = c(0.8, 1),
    post = c(1.2, 1),
    row.names = c("cat", "dog")
  ),
  sd = 1,
  id = "pet_id",
  dv = "happiness",
  r = 0.5,
  long = TRUE,
  rep = 1000
)

analyse <- function(data){
  
  a <- aov_4(happiness ~ pet * (time | pet_id),data=data)
  
    # return anova_table for GG-corrected DF
    as_tibble(a$anova_table, rownames = "term") %>% 
    mutate(term = factor(term, levels = term))  %>%  # keeps terms in order
    rename(p.value = `Pr(>F)`) # fixes annoying p.value name
}

pethappy_sim <- map_df(pethappy100$data,analyse)

pethappy_sim |>
  group_by(term) |>
  summarise(power = mean(p.value < 0.05),
            mean_pes = mean(pes),
            .groups = "drop") %>% 
  mutate(sample_size=n)
}

sims <- map_df(sample_sizes,create_dfs)

```


```{r}
sims %>% ggplot(
  aes(
    y=power, 
    x = sample_size, 
    color=term)
  ) + 
  geom_point() +
  geom_line()
```

```{r}

```




